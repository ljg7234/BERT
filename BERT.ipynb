{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ljg7234/BERT/blob/main/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gZoDWg6qJVNw"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PQmn9NRsKNUh"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def forward(self,query,key,value,mask = None,dropout = None):\n",
        "        scores = torch.matmul(query,key.transpose(-2,-1)) / math.sqrt(query.size(-1))\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        p_attn = F.softmax(scores,dim = -1)\n",
        "\n",
        "        if dropout is not None:\n",
        "            p_attn = dropout(p_attn)\n",
        "\n",
        "        return torch.matmul(p_attn,value),p_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bIb3X-UZK1YT"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self,h,d_model,dropout = 0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % h == 0\n",
        "\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "\n",
        "        self.linear_layers = nn.ModuleList([nn.Linear(d_model,d_model) for _ in range(3)])\n",
        "        self.output_linear = nn.Linear(d_model,d_model)\n",
        "        self.attention = Attention()\n",
        "        self.dropout = nn.Dropout(p = dropout)\n",
        "\n",
        "    def forward(self,query,key,value,mask = None):\n",
        "        batch_size = query.size(0)\n",
        "        query,key,value = [l(x).view(batch_size,-1,self.h,self.d_k).transpose(1,2)\n",
        "                            for l,x in zip(self.linear_layers, (query,key,value))]\n",
        "\n",
        "        x, attn = self.attention(query,key,value,mask = mask,dropout = self.dropout)\n",
        "\n",
        "        x = x.transpose(1,2).contiguous().view(batch_size,-1,self.h * self.d_k)\n",
        "        return self.output_linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9oneskKNK1bI"
      },
      "outputs": [],
      "source": [
        "class TokenEmbedding(nn.Embedding):\n",
        "    def __init__(self,vocab_size,embed_size = 512):\n",
        "        super().__init__(vocab_size,embed_size,padding_idx = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NozobxBWK1d_"
      },
      "outputs": [],
      "source": [
        "class SegmentEmbedding(nn.Embedding):\n",
        "    def __init__(self,embed_size = 512):\n",
        "        super().__init__(3,embed_size,padding_idx= 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cGs00dWdK1gV"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self,d_model,max_len = 512):\n",
        "        super().__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len,d_model).float()\n",
        "        pe.requires_grad = False\n",
        "\n",
        "        position = torch.arange(0,max_len).float().unsqueeze(1)\n",
        "        div_term = (torch.arange(0,d_model,2).float() * -(math.log(10000.0) / d_model)).exp()\n",
        "\n",
        "        pe[:,0::2] = torch.sin(position * div_term)\n",
        "        pe[:,1::2] = torch.cos(position * div_term)\n",
        "\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe',pe)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return(self.pe[:,:x.size(1)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8FYYXLfmPUY2"
      },
      "outputs": [],
      "source": [
        "class BERTEmbedding(nn.Module):\n",
        "    def __init__(self,vocab_size,embed_size,dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.token = TokenEmbedding(vocab_size = vocab_size,embed_size = embed_size)\n",
        "        self.position = PositionalEmbedding(d_model = self.token.embedding_dim)\n",
        "        self.segment = SegmentEmbedding(embed_size=self.token.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p = dropout)\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "    def forward(self,sequence,segment_label):\n",
        "        x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8aMREBkepLiy"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "    def forward(self,x):\n",
        "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x,3))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eIbK7TOxpLk-"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self,features,eps = 1e-6):\n",
        "        super().__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self,x):\n",
        "        mean = x.mean(-1,keepdim = True)\n",
        "        std = x.std(-1,keepdim = True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uT0iVN-IpLoJ"
      },
      "outputs": [],
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "    def __init__(self,size,dropout):\n",
        "        super().__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,x,sublayer):\n",
        "        return x + self.dropout(sublayer(self.norm(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7aX5L_GvtIBr"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self,d_model,d_ff,dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.w_1 = nn.Linear(d_model,d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff,d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = GELU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.w_2(self.dropout(self.activation(self.w_1(x))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i6HSRavXpLs1"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self,hidden,attn_heads,feed_forward_hidden,dropout):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadedAttention(h = attn_heads, d_model = hidden)\n",
        "        self.feed_forward = PositionwiseFeedForward(d_model = hidden, d_ff = feed_forward_hidden,dropout = dropout)\n",
        "        self.input_sublayer = SublayerConnection(size = hidden, dropout = dropout)\n",
        "        self.output_sublayer = SublayerConnection(size = hidden,dropout = dropout)\n",
        "        self.dropout = nn.Dropout(p = dropout)\n",
        "\n",
        "    def forward(self,x,mask):\n",
        "        x = self.input_sublayer(x, lambda _x: self.attention.forward(_x,_x,_x,mask = mask))\n",
        "        x = self.output_sublayer(x,self.feed_forward)\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jXdBYIseujPX"
      },
      "outputs": [],
      "source": [
        "class BERT(nn.Module):\n",
        "    def __init__(self,vocab_size,hidden = 768,n_layers = 12,attn_heads = 12,dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.hidden = hidden\n",
        "        self.n_layers = n_layers\n",
        "        self.attn_heads = attn_heads\n",
        "\n",
        "        self.feed_forward_hidden = hidden * 4\n",
        "        self.embedding = BERTEmbedding(vocab_size = vocab_size,embed_size= hidden)\n",
        "        self.transformer_blocks = nn.ModuleList(\n",
        "            [TransformerBlock(hidden,attn_heads,hidden * 4,dropout) for _ in range(n_layers)]\n",
        "        )\n",
        "\n",
        "    def forward(self,x,segment_info):\n",
        "        mask = (x > 0).unsqueeze(1).repeat(1,x.size(1),1).unsqueeze(1)\n",
        "\n",
        "        x = self.embedding(x,segment_info)\n",
        "\n",
        "        for transformer in self.transformer_blocks:\n",
        "            x = transformer.forward(x,mask)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0deoqzU23SBe"
      },
      "outputs": [],
      "source": [
        "class NextSentencePrediction(nn.Module):\n",
        "    def __init__(self,hidden):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(hidden,hidden)\n",
        "        self.activation = nn.Tanh()\n",
        "        self.output = nn.Linear(hidden,2)\n",
        "        self.softmax = nn.LogSoftmax(dim = -1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.linear(x[:,0])\n",
        "        x = self.activation(x)\n",
        "        return self.softmax(self.output(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9C4BYxrq3SED"
      },
      "outputs": [],
      "source": [
        "class MaskedLanguageModel(nn.Module):\n",
        "    def __init__(self,hidden,vocab_size):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(hidden,vocab_size)\n",
        "        self.softmax = nn.LogSoftmax(dim = -1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.softmax(self.linear(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2NZoeongyhdd"
      },
      "outputs": [],
      "source": [
        "class BERTLM(nn.Module):\n",
        "    def __init__(self,bert : BERT,vocab_size):\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        self.next_sentence = NextSentencePrediction(self.bert.hidden)\n",
        "        self.mask_lm = MaskedLanguageModel(self.bert.hidden,vocab_size)\n",
        "\n",
        "    def forward(self,x,segment_label):\n",
        "        x = self.bert(x,segment_label)\n",
        "        return self.next_sentence(x),self.mask_lm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_3F-P_Ym5xtq"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from tqdm.auto import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "class TorchVocab(object):\n",
        "    def __init__(self,counter,max_size = None,min_freq = 1,specials = ['<pad>','<oov>'],\n",
        "                 vectors = None, unk_init = None, vectors_cache = None):\n",
        "        self.freqs = counter\n",
        "        counter = counter.copy()\n",
        "        min_freq = max(min_freq,1)\n",
        "\n",
        "        self.itos = list(specials)\n",
        "        for tok in specials:\n",
        "            del counter[tok]\n",
        "\n",
        "        max_size = None if max_size is None else max_size + len(self.itos)\n",
        "\n",
        "        words_and_frequencies = sorted(counter.items(),key = lambda tup: tup[0])\n",
        "        words_and_frequencies.sort(key = lambda tup: tup[1],reverse = True)\n",
        "\n",
        "        for word,freq in words_and_frequencies:\n",
        "            if freq < min_freq or len(self.itos) == max_size:\n",
        "                break\n",
        "            self.itos.append(word)\n",
        "\n",
        "        self.stoi = {tok: i for i,tok in enumerate(self.itos)}\n",
        "\n",
        "        self.vectors = None\n",
        "        if vectors is not None:\n",
        "            self.load_vectors(vectors,unk_init = unk_init,cache = vectors_cache)\n",
        "        else:\n",
        "            assert unk_init is None and vectors_cache is None\n",
        "\n",
        "    def __eq__(self,other):\n",
        "        if self.freqs != other.freqs:\n",
        "            return False\n",
        "        if self.stoi != other.stoi:\n",
        "            return False\n",
        "        if self.itos != other.itos:\n",
        "            return False\n",
        "        if self.vectors != other.vectors:\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    def vocab_rerank(self):\n",
        "        self.stoi = {word: i for i,word in enumerate(self.itos)}\n",
        "\n",
        "    def extend(self,v,sort = False):\n",
        "        words = sorted(v.itos) if sort else v.itos\n",
        "        for w in words:\n",
        "            if w not in self.stoi:\n",
        "                self.itos.append(w)\n",
        "                self.stoi[w] = len(self.itos) -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cdA5mY-C_V0l"
      },
      "outputs": [],
      "source": [
        "class Vocab(TorchVocab):\n",
        "    def __init__(self,counter,max_size = None,min_freq = 1):\n",
        "        self.pad_index = 0\n",
        "        self.unk_index = 1\n",
        "        self.eos_index = 2\n",
        "        self.sos_index = 3\n",
        "        self.mask_index = 4\n",
        "        super().__init__(counter,specials = [\"<pad>\",\"<unk>\",\"<eos>\",\"<sos>\",\"<mask>\"],\n",
        "                         max_size = max_size,min_freq = min_freq)\n",
        "\n",
        "    def to_seq(self,sentence,seq_len,with_eos = False,with_sos = False) -> list:\n",
        "        pass\n",
        "\n",
        "    def from_seq(self,seq,join = False,with_pad = False):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vocab(vocab_path: str) -> 'Vocab':\n",
        "        with open(vocab_path,\"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    def save_vocab(self,vocab_path):\n",
        "        with open(vocab_path,\"wb\") as f:\n",
        "            pickle.dump(self,f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Xxb2qRLMBknU"
      },
      "outputs": [],
      "source": [
        "class WordVocab(Vocab):\n",
        "    def __init__(self,texts,max_size = None,min_freq = 1):\n",
        "        print(\"Building Vocab\")\n",
        "        counter = Counter()\n",
        "        for line in tqdm(texts):\n",
        "            if isinstance(line,list):\n",
        "                words = line\n",
        "            else:\n",
        "                words = line.replace(\"\\n\", \"\").split()\n",
        "            for word in words:\n",
        "                counter[word] += 1\n",
        "        super().__init__(counter,max_size = max_size,min_freq= min_freq)\n",
        "\n",
        "    def to_seq(self,sentence,seq_len = None,with_eos = False,with_sos = False,with_len = False):\n",
        "        if isinstance(sentence,str):\n",
        "            sentence = sentence.split()\n",
        "\n",
        "        seq = [self.stoi.get(word,self.unk_index) for word in sentence]\n",
        "\n",
        "        if with_eos:\n",
        "            seq += [self.eos_index]\n",
        "        if with_sos:\n",
        "            seq = [self.sos_index] + seq\n",
        "\n",
        "        origin_seq_len = len(seq)\n",
        "\n",
        "        if seq_len is None:\n",
        "            pass\n",
        "        elif len(seq) <= seq_len:\n",
        "            seq += [self.pad_index for _ in range(seq_len - len(seq))]\n",
        "        else:\n",
        "            seq = seq[:seq_len]\n",
        "\n",
        "        return (seq,origin_seq_len) if with_len else seq\n",
        "\n",
        "    def from_seq(self,seq,join = False,with_pad = False):\n",
        "        words = [self.itos[idx]\n",
        "                 if idx < len(self.itos)\n",
        "                 else \"<%d>\" %idx\n",
        "                 for idx in seq\n",
        "                 if not with_pad or idx != self.pad_index]\n",
        "        return \" \".join(words) if join else words\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vocab(vocab_path: str) -> 'WordVocab':\n",
        "        with open(vocab_path,\"rb\") as f:\n",
        "            return pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qey508LCBksw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self,corpus_path,vocab,seq_len,encoding = \"utf-8\",corpus_lines = None,on_memory=True):\n",
        "        self.vocab = vocab\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        self.on_memory = on_memory\n",
        "        self.corpus_lines = corpus_lines\n",
        "        self.corpus_path = corpus_path\n",
        "        self.encoding = encoding\n",
        "        self.vocab_unk_index = vocab.unk_index\n",
        "\n",
        "        with open(corpus_path,\"r\",encoding = encoding) as f:\n",
        "            if on_memory:\n",
        "                self.lines = [line.strip().split(\"\\t\")\n",
        "                                for line in f\n",
        "                              if \"\\t\" in line]\n",
        "                self.corpus_lines = len(self.lines)\n",
        "            else:\n",
        "                self.corpus_lines = 0\n",
        "                for line in f:\n",
        "                    if line.strip(): self.corpus_lines += 1\n",
        "        if self.corpus_lines == 0:\n",
        "            raise ValueError(\"데이터셋이 비어있습니다. corpus.txt 파일을 확인하세요 \")\n",
        "\n",
        "        if not on_memory:\n",
        "            self.file = open(corpus_path, \"r\", encoding=encoding)\n",
        "            self.random_file = open(corpus_path, \"r\", encoding=encoding)\n",
        "            for _ in range(random.randint(0, self.corpus_lines - 1)):\n",
        "                next(self.random_file)\n",
        "    def __len__(self):\n",
        "        return self.corpus_lines\n",
        "\n",
        "    def random_word(self,sentence):\n",
        "        tokens = sentence.split()\n",
        "        output_label = []\n",
        "\n",
        "        for i,token in enumerate(tokens):\n",
        "            prob = random.random()\n",
        "            if prob < 0.15:\n",
        "                prob /= 0.15\n",
        "                if prob < 0.8:\n",
        "                    tokens[i] = self.vocab.mask_index\n",
        "                elif prob < 0.9:\n",
        "                    tokens[i] = random.randrange(len(self.vocab))\n",
        "                else:\n",
        "                    tokens[i] = self.vocab.stoi.get(token,self.vocab.unk_index)\n",
        "\n",
        "                output_label.append(self.vocab.stoi.get(token,self.vocab.unk_index))\n",
        "            else:\n",
        "                tokens[i] = self.vocab.stoi.get(token,self.vocab.unk_index)\n",
        "                output_label.append(0)\n",
        "\n",
        "        return tokens,output_label\n",
        "\n",
        "    def get_corpus_line(self,item):\n",
        "        if self.on_memory:\n",
        "            return self.lines[item][0],self.lines[item][1]\n",
        "        else:\n",
        "            line = self.file.__next__()\n",
        "            if line is None:\n",
        "                self.file.close()\n",
        "                self.file = open(self.corpus_path,\"r\",encoding = self.encoding)\n",
        "                line = self.file.__next__()\n",
        "            t1,t2 = line[:-1].split(\"\\t\")\n",
        "            return t1,t2\n",
        "\n",
        "    def get_random_line(self):\n",
        "        if self.on_memory:\n",
        "            return self.lines[random.randrange(len(self.lines))][1]\n",
        "\n",
        "        line = self.file.__next__()\n",
        "        if line is None:\n",
        "            self.file.close()\n",
        "            self.file = open(self.corpus_path,\"r\",encoding = self.encoding)\n",
        "            for _ in range(random.randint(self.corpus_lines if self.corpus_lines < 1000 else 1000)):\n",
        "                self.random_file.__next__()\n",
        "            line = self.random_file.__next__()\n",
        "        return line[:-1].split(\"\\t\")[1]\n",
        "\n",
        "    def random_sent(self,index):\n",
        "        t1,t2 = self.get_corpus_line(index)\n",
        "\n",
        "        if random.random() > 0.5:\n",
        "            return t1,t2,0\n",
        "        else:\n",
        "            return t1,self.get_random_line(),1\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        t1, t2, is_next_label = self.random_sent(item)\n",
        "        t1_random, t1_label = self.random_word(t1)\n",
        "        t2_random, t2_label = self.random_word(t2)\n",
        "\n",
        "        t1 = [self.vocab.sos_index] + t1_random + [self.vocab.eos_index]\n",
        "        t2 = t2_random + [self.vocab.eos_index]\n",
        "\n",
        "        t1_label = [self.vocab.pad_index] + t1_label + [self.vocab.pad_index]\n",
        "        t2_label = t2_label + [self.vocab.pad_index]\n",
        "\n",
        "        while len(t1) + len(t2) > self.seq_len:\n",
        "            if len(t1) > len(t2):\n",
        "                t1.pop()\n",
        "                t1_label.pop()\n",
        "            else:\n",
        "                t2.pop()\n",
        "                t2_label.pop()\n",
        "\n",
        "        bert_input = (t1 + t2)[:self.seq_len]\n",
        "        bert_label = (t1_label + t2_label)[:self.seq_len]\n",
        "\n",
        "        t1_len = len(t1)\n",
        "        segment_label = ([1] * t1_len + [2] * (len(bert_input) - t1_len))[:self.seq_len]\n",
        "\n",
        "\n",
        "        padding = [self.vocab.pad_index] * (self.seq_len - len(bert_input))\n",
        "        bert_input.extend(padding)\n",
        "        bert_label.extend(padding)\n",
        "        segment_label.extend(padding)\n",
        "\n",
        "        output = {\"bert_input\": bert_input,\n",
        "                  \"bert_label\": bert_label,\n",
        "                  \"segment_label\": segment_label,\n",
        "                  \"is_next\": is_next_label}\n",
        "\n",
        "        return {key: torch.tensor(value) for key, value in output.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "usYMg5YPBkvX"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class BERTTrainer:\n",
        "    def __init__(self,bert: BERT,vocab_size: int,\n",
        "                 train_dataloader: DataLoader,test_dataloader: DataLoader = None,\n",
        "                 lr:float = 1e-4, betas = (0.9,0.999),weight_decay: float = 0.01, warmup_steps = 10,\n",
        "                 with_cuda = True,cuda_devices = None,log_freq: int = 10):\n",
        "        cuda_condition = torch.cuda.is_available() and with_cuda\n",
        "        self.device = torch.device(\"cuda:0\" if cuda_condition else \"cpu\")\n",
        "\n",
        "        self.bert = bert\n",
        "        self.model = BERTLM(bert,vocab_size).to(self.device)\n",
        "\n",
        "        if with_cuda and torch.cuda.device_count() > 1:\n",
        "            print(\"Using %d GPUS for BERT\" % torch.cuda.device_count())\n",
        "            self.model = nn.DataParallel(self.model,device_ids = cuda_devices)\n",
        "\n",
        "        self.train_data = train_dataloader\n",
        "        self.test_data = test_dataloader\n",
        "\n",
        "        self.optim = Adam(self.model.parameters(),lr = lr,betas = betas,weight_decay=weight_decay)\n",
        "\n",
        "        self.criterion_mlm = nn.NLLLoss(ignore_index = 0)\n",
        "        self.criterion_nsp = nn.NLLLoss()\n",
        "\n",
        "        self.log_freq = log_freq\n",
        "\n",
        "        print(\"Total Parameters:\",sum([p.nelement() for p in self.model.parameters()]))\n",
        "\n",
        "    def test(self,epoch):\n",
        "        self.iteration(epoch,self.test_data,train = False)\n",
        "\n",
        "    def iteration(self,epoch,data_loader,train = True):\n",
        "        str_code = \"train\" if train else \"test\"\n",
        "\n",
        "        data_iter = tqdm(enumerate(data_loader),\n",
        "                         total = len(data_loader),\n",
        "                         disable = True)\n",
        "\n",
        "        avg_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_element = 0\n",
        "        avg_next_loss = 0.0\n",
        "        avg_mask_loss = 0.0\n",
        "\n",
        "        for i,data in data_iter:\n",
        "            data = {key: value.to(self.device) for key,value in data.items()}\n",
        "            next_sent_output,mask_lm_output = self.model.forward(data[\"bert_input\"],data[\"segment_label\"])\n",
        "            next_loss = self.criterion_nsp(next_sent_output,data[\"is_next\"])\n",
        "            mask_loss = self.criterion_mlm(mask_lm_output.transpose(1,2),data[\"bert_label\"])\n",
        "            loss = next_loss + mask_loss\n",
        "\n",
        "            if train:\n",
        "                self.optim.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optim.step()\n",
        "\n",
        "            correct = next_sent_output.argmax(dim = -1).eq(data[\"is_next\"]).sum().item()\n",
        "            avg_loss += loss.item()\n",
        "            avg_next_loss += next_loss.item()\n",
        "            avg_mask_loss += mask_loss.item()\n",
        "            total_correct += correct\n",
        "            total_element += data[\"is_next\"].nelement()\n",
        "\n",
        "        final_loss = avg_loss / len(data_loader)\n",
        "        final_acc = total_correct * 100.0 / total_element\n",
        "        final_next_loss = avg_next_loss / len(data_loader)\n",
        "        final_mask_loss = avg_mask_loss / len(data_loader)\n",
        "        return final_loss, final_next_loss,final_mask_loss,final_acc\n",
        "\n",
        "    def save(self,epoch,file_path = \"output/bert_trained.model\"):\n",
        "        output_path = file_path + \".ep%d\" % epoch\n",
        "        torch.save(self.model,output_path)\n",
        "        self.bert.to(self.device)\n",
        "        print(\"EP:%d Model Saved on:\"  %epoch,output_path)\n",
        "        return output_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "48466d5d0d444d778ad8f8304f992e4c",
            "4016ecf43d9e408a89b3cceea23c3295",
            "fee80d488bd0464b9b150051c17a5753",
            "f17103dd8d534cfc88c8949a7b7f5a62",
            "5b2e3d3caa4d4532825efb5d01580156",
            "e538b1d0ef6e4ee39d0275be56029526",
            "abcab4e3837b4fc09956345698a4daed",
            "7b5e0f505f8a44d599a351cd838dcc38",
            "58f344e637bb43dcbdff349b762df6ff",
            "2279dd8fc2cb4628b89d05bb4fadf1a5",
            "1c0c76a99427484597532de4dcb08a0d"
          ]
        },
        "id": "qRTV6hE05fGX",
        "outputId": "ce7eb5eb-d0af-4b42-b511-0cc7d5266f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Vocab\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48466d5d0d444d778ad8f8304f992e4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토이 데이터 생성 완료! 문장 쌍: 8700개, 사전 크기: 94\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "import re\n",
        "\n",
        "train_dataset_path = \"corpus.txt\"\n",
        "vocab_path = \"vocab.txt\"\n",
        "output_dir = \"output\"\n",
        "\n",
        "if os.path.exists(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "os.makedirs(output_dir)\n",
        "\n",
        "toy_sentences = [\n",
        "    \"a cat sits on a mat .\",\n",
        "    \"that mat is on the floor .\",\n",
        "    \"one dog runs in a park .\",\n",
        "    \"this park is very big .\",\n",
        "    \"i like to eat apples .\",\n",
        "    \"apples are very sweet .\",\n",
        "    \"she reads a thick book .\",\n",
        "    \"this book has many pages .\",\n",
        "    \"he drives a fast car .\",\n",
        "    \"that car is very expensive .\",\n",
        "    \"birds fly in a sky .\",\n",
        "    \"sky is blue and clear .\",\n",
        "    \"fish swim in water .\",\n",
        "    \"water is cold and deep .\",\n",
        "    \"a chef cooks a meal .\",\n",
        "    \"some meal is on a table .\",\n",
        "    \"sun rises in a morning .\",\n",
        "    \"morning is bright and warm .\",\n",
        "    \"rain falls from clouds .\",\n",
        "    \"clouds are dark and heavy .\",\n",
        "    \"flowers grow in a garden .\",\n",
        "    \"garden is full of colors .\",\n",
        "    \"a teacher speaks to a class .\",\n",
        "    \"every class is listening now .\",\n",
        "    \"moon shines in a night .\",\n",
        "    \"night is quiet and dark .\",\n",
        "    \"a boy plays a guitar .\",\n",
        "    \"guitar sounds very loud .\",\n",
        "    \"we learn deep learning .\",\n",
        "    \"learning is very interesting .\"\n",
        "]\n",
        "\n",
        "formatted_pairs = []\n",
        "for _ in range(300):\n",
        "    for i in range(len(toy_sentences) - 1):\n",
        "        formatted_pairs.append(f\"{toy_sentences[i]}\\t{toy_sentences[i+1]}\")\n",
        "\n",
        "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(formatted_pairs))\n",
        "\n",
        "with open(\"corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    vocab = WordVocab(f, min_freq=1)\n",
        "\n",
        "vocab.save_vocab(\"vocab.txt\")\n",
        "print(f\"토이 데이터 생성 완료! 문장 쌍: {len(formatted_pairs)}개, 사전 크기: {len(vocab)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden = 32\n",
        "layers = 2\n",
        "attn_heads = 2\n",
        "seq_len = 20\n",
        "batch_size = 16\n",
        "epochs = 100\n",
        "lr = 1e-3\n",
        "\n",
        "train_dataset = BERTDataset(train_dataset_path,vocab,seq_len = seq_len)\n",
        "train_data_loader = DataLoader(train_dataset,batch_size = batch_size,num_workers = 2)"
      ],
      "metadata": {
        "id": "hnThx8hYnsqq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuF9tZ-1Uqf-",
        "outputId": "b6661310-2d6b-4be0-c5de-433341effc17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building BERT model...\n",
            "Total Parameters: 32736\n",
            "Training Start...\n",
            "Epoch   5 | Total: 3.6833 | NSP: 0.6936 | MLM: 2.9896 | Acc: 50.01%\n",
            "EP:4 Model Saved on: output/bert.model.ep4\n",
            "Epoch  10 | Total: 3.2874 | NSP: 0.6933 | MLM: 2.5941 | Acc: 49.64%\n",
            "EP:9 Model Saved on: output/bert.model.ep9\n",
            "Epoch  15 | Total: 3.1986 | NSP: 0.6927 | MLM: 2.5059 | Acc: 51.05%\n",
            "EP:14 Model Saved on: output/bert.model.ep14\n",
            "Epoch  20 | Total: 3.1284 | NSP: 0.6919 | MLM: 2.4364 | Acc: 50.56%\n",
            "EP:19 Model Saved on: output/bert.model.ep19\n",
            "Epoch  25 | Total: 3.0750 | NSP: 0.6919 | MLM: 2.3830 | Acc: 51.23%\n",
            "EP:24 Model Saved on: output/bert.model.ep24\n",
            "Epoch  30 | Total: 3.0009 | NSP: 0.6918 | MLM: 2.3092 | Acc: 52.10%\n",
            "EP:29 Model Saved on: output/bert.model.ep29\n",
            "Epoch  35 | Total: 2.9998 | NSP: 0.6925 | MLM: 2.3073 | Acc: 52.21%\n",
            "EP:34 Model Saved on: output/bert.model.ep34\n",
            "Epoch  40 | Total: 2.9738 | NSP: 0.6924 | MLM: 2.2815 | Acc: 51.31%\n",
            "EP:39 Model Saved on: output/bert.model.ep39\n",
            "Epoch  45 | Total: 2.9806 | NSP: 0.6912 | MLM: 2.2894 | Acc: 52.97%\n",
            "EP:44 Model Saved on: output/bert.model.ep44\n",
            "Epoch  50 | Total: 2.9529 | NSP: 0.6919 | MLM: 2.2609 | Acc: 50.93%\n",
            "EP:49 Model Saved on: output/bert.model.ep49\n",
            "Epoch  55 | Total: 2.9394 | NSP: 0.6912 | MLM: 2.2483 | Acc: 52.57%\n",
            "EP:54 Model Saved on: output/bert.model.ep54\n",
            "Epoch  60 | Total: 2.8871 | NSP: 0.6889 | MLM: 2.1982 | Acc: 53.71%\n",
            "EP:59 Model Saved on: output/bert.model.ep59\n",
            "Epoch  65 | Total: 2.8534 | NSP: 0.6885 | MLM: 2.1648 | Acc: 54.13%\n",
            "EP:64 Model Saved on: output/bert.model.ep64\n",
            "Epoch  70 | Total: 2.7586 | NSP: 0.6873 | MLM: 2.0714 | Acc: 54.21%\n",
            "EP:69 Model Saved on: output/bert.model.ep69\n",
            "Epoch  75 | Total: 2.5250 | NSP: 0.6892 | MLM: 1.8358 | Acc: 52.76%\n",
            "EP:74 Model Saved on: output/bert.model.ep74\n",
            "Epoch  80 | Total: 2.3461 | NSP: 0.6878 | MLM: 1.6583 | Acc: 53.84%\n",
            "EP:79 Model Saved on: output/bert.model.ep79\n",
            "Epoch  85 | Total: 2.2802 | NSP: 0.6406 | MLM: 1.6395 | Acc: 62.68%\n",
            "EP:84 Model Saved on: output/bert.model.ep84\n",
            "Epoch  90 | Total: 2.2131 | NSP: 0.5986 | MLM: 1.6146 | Acc: 67.21%\n",
            "EP:89 Model Saved on: output/bert.model.ep89\n",
            "Epoch  95 | Total: 2.1726 | NSP: 0.5669 | MLM: 1.6058 | Acc: 70.34%\n",
            "EP:94 Model Saved on: output/bert.model.ep94\n",
            "Epoch 100 | Total: 2.1028 | NSP: 0.5482 | MLM: 1.5546 | Acc: 72.41%\n",
            "EP:99 Model Saved on: output/bert.model.ep99\n"
          ]
        }
      ],
      "source": [
        "print(\"Building BERT model...\")\n",
        "bert = BERT(len(vocab),hidden = hidden, n_layers = layers,attn_heads = attn_heads)\n",
        "\n",
        "trainer = BERTTrainer(bert,len(vocab),train_dataloader = train_data_loader,lr = lr,with_cuda = True)\n",
        "\n",
        "print(\"Training Start...\")\n",
        "for epoch in range(epochs):\n",
        "    loss,next_l,mask_l,acc= trainer.iteration(epoch,train_data_loader,train = True)\n",
        "\n",
        "    if(epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch {epoch+1:3d} | Total: {loss:.4f} | NSP: {next_l:.4f} | MLM: {mask_l:.4f} | Acc: {acc:.2f}%\")\n",
        "        trainer.save(epoch, \"output/bert.model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pS6CISuyuwD",
        "outputId": "c6a6cb49-01cb-4ee4-f57b-90b2a9db79cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 테스트 결과 ---\n",
            "입력 문장 A: birds fly in a sky .\n",
            "입력 문장 B: sky is <mask style> and clear .\n",
            "문장 관계 예측: 연속됨(IsNext)\n",
            "단어 예측 결과: blue\n"
          ]
        }
      ],
      "source": [
        "model_path = \"output/bert.model.ep99\"\n",
        "vocab_path = \"vocab.txt\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(vocab_path, \"rb\") as f:\n",
        "    vocab = pickle.load(f)\n",
        "\n",
        "model = torch.load(model_path, map_location=device, weights_only=False)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "text_a = \"birds fly in a sky .\"\n",
        "text_b = \"sky is <mask style> and clear .\"\n",
        "\n",
        "tokens_a = text_a.split()\n",
        "tokens_b = [\"sky\", \"is\", \"<mask style>\", \"and\", \"clear\", \".\"]\n",
        "\n",
        "input_ids = [vocab.sos_index] + \\\n",
        "            [vocab.stoi.get(t, vocab.unk_index) for t in tokens_a] + \\\n",
        "            [vocab.eos_index] + \\\n",
        "            [vocab.stoi.get(t, vocab.unk_index) if t != \"<mask style>\" else vocab.mask_index for t in tokens_b] + \\\n",
        "            [vocab.eos_index]\n",
        "\n",
        "segment_label = [1] * (len(tokens_a) + 2) + [2] * (len(tokens_b) + 1)\n",
        "\n",
        "input_tensor = torch.tensor([input_ids]).to(device)\n",
        "segment_tensor = torch.tensor([segment_label]).to(device)\n",
        "\n",
        "try:\n",
        "    mask_pos = input_ids.index(vocab.mask_index)\n",
        "    with torch.no_grad():\n",
        "        nsp_output, mlm_output = model(input_tensor, segment_tensor)\n",
        "\n",
        "        is_next = nsp_output.argmax(dim=-1).item()\n",
        "        print(f\"--- 테스트 결과 ---\")\n",
        "        print(f\"입력 문장 A: {text_a}\")\n",
        "        print(f\"입력 문장 B: {text_b}\")\n",
        "        print(f\"문장 관계 예측: {'연속됨(IsNext)' if is_next == 0 else '상관없음(NotNext)'}\")\n",
        "\n",
        "        predict_id = mlm_output[0, mask_pos].argmax(dim=-1).item()\n",
        "        print(f\"단어 예측 결과: {vocab.itos[predict_id]}\")\n",
        "\n",
        "except ValueError:\n",
        "    print(\"입력 데이터에 <mask style> 토큰이 없습니다.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1DjDCvLZwXji5-O42i-kXZR8ASUPVl9Sn",
      "authorship_tag": "ABX9TyMMl+3mQ8dpYbUT+lKdzZdm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48466d5d0d444d778ad8f8304f992e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4016ecf43d9e408a89b3cceea23c3295",
              "IPY_MODEL_fee80d488bd0464b9b150051c17a5753",
              "IPY_MODEL_f17103dd8d534cfc88c8949a7b7f5a62"
            ],
            "layout": "IPY_MODEL_5b2e3d3caa4d4532825efb5d01580156"
          }
        },
        "4016ecf43d9e408a89b3cceea23c3295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e538b1d0ef6e4ee39d0275be56029526",
            "placeholder": "​",
            "style": "IPY_MODEL_abcab4e3837b4fc09956345698a4daed",
            "value": ""
          }
        },
        "fee80d488bd0464b9b150051c17a5753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5e0f505f8a44d599a351cd838dcc38",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58f344e637bb43dcbdff349b762df6ff",
            "value": 1
          }
        },
        "f17103dd8d534cfc88c8949a7b7f5a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2279dd8fc2cb4628b89d05bb4fadf1a5",
            "placeholder": "​",
            "style": "IPY_MODEL_1c0c76a99427484597532de4dcb08a0d",
            "value": " 8700/? [00:00&lt;00:00, 37807.87it/s]"
          }
        },
        "5b2e3d3caa4d4532825efb5d01580156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e538b1d0ef6e4ee39d0275be56029526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abcab4e3837b4fc09956345698a4daed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b5e0f505f8a44d599a351cd838dcc38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "58f344e637bb43dcbdff349b762df6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2279dd8fc2cb4628b89d05bb4fadf1a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c0c76a99427484597532de4dcb08a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}